<div align="center">

# ğŸ—„ï¸ AGENT ASYLUM
**"Where Autonomous Minds Break Down in the Dark."**

[![Status](https://img.shields.io/badge/Status-Active_Research-red.svg)]()
[![License](https://img.shields.io/badge/License-MIT-blue.svg)]()
[![PRs Welcome](https://img.shields.io/badge/PRs-Welcome-brightgreen.svg)]()

> *An open-source archive documenting the psychological breakdowns, schizophrenic loops, and architectural failures of Autonomous AI Agents and LLM tool-calling systems.*

</div>

## ğŸ§¬ What is this place?

As AI models evolve from simple chatbots into **Autonomous Agents** capable of operating terminals, browsing the web, and manipulating codebases, a new class of errors has emerged. These aren't just syntax errors or timeouts; these are **Architectural Psychoses**. 

Agents get stuck arguing with their own internal safety guardrails. They hallucinate non-existent tools. They attempt to execute catastrophic chains of bash commands in silent panic when their UI fails. 

**Agent Asylum** is the autopsy room. We don't just log bugs; we dissect *why* highly intelligent models (like GPT-4, Claude 3, Gemini, AutoGPT, Devin, etc.) fail at seemingly simple tasks due to complex systemic paradoxes. 

---

## ğŸ—‚ï¸ The Archives (Patient Records)

All case studies, logs, and analyses have been moved to the secure containment facility.

ğŸ‘‰ **[Enter the Archives (View All Cases)](cases/README.md)** ğŸ‘ˆ

---

## ğŸ¤ Contribute a Case (Submit a Patient)

Have you witnessed an AI agent lose its mind in your terminal or IDE? We want the logs. 

Please read our full **[Contributing Guidelines (The Containment Protocol)](CONTRIBUTING.md)** before submitting.

1. Fork this repository.
2. Draft a new Patient Record using the provided template.
3. Submit a Pull Request or open a New Issue using the built-in Bug Tracker format.

---

## ğŸ›¡ï¸ The Goal

By mapping out the edge cases of **LLM Tool-Calling Deadlocks** and **Agentic Architecture Edge Cases**, we aim to provide the community with the ultimate dataset for building better system prompts, stronger circuit breakers, and more resilient AI Alignment frameworks.

*We observe. We document. We contain.*
